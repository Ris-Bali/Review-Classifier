{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import functools\nimport sys\n\nimport datasets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchtext\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:28:37.299995Z","iopub.execute_input":"2022-02-08T13:28:37.301024Z","iopub.status.idle":"2022-02-08T13:28:39.586570Z","shell.execute_reply.started":"2022-02-08T13:28:37.300898Z","shell.execute_reply":"2022-02-08T13:28:39.585621Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Initializing the seed","metadata":{}},{"cell_type":"code","source":"seed = 0\n\ntorch.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:28:39.588759Z","iopub.execute_input":"2022-02-08T13:28:39.589226Z","iopub.status.idle":"2022-02-08T13:28:39.602788Z","shell.execute_reply.started":"2022-02-08T13:28:39.589184Z","shell.execute_reply":"2022-02-08T13:28:39.601440Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"train_data, test_data = datasets.load_dataset('imdb', split=['train', 'test'])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:28:39.604690Z","iopub.execute_input":"2022-02-08T13:28:39.605035Z","iopub.status.idle":"2022-02-08T13:29:28.960686Z","shell.execute_reply.started":"2022-02-08T13:28:39.604994Z","shell.execute_reply":"2022-02-08T13:29:28.959625Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Initializing  a tokenizer","metadata":{}},{"cell_type":"code","source":"\ntokenizer = torchtext.data.utils.get_tokenizer('basic_english')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:28.963234Z","iopub.execute_input":"2022-02-08T13:29:28.964067Z","iopub.status.idle":"2022-02-08T13:29:28.969868Z","shell.execute_reply.started":"2022-02-08T13:29:28.964022Z","shell.execute_reply":"2022-02-08T13:29:28.968627Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Function for tokenizing the data","metadata":{}},{"cell_type":"code","source":"def tokenize_data(example, tokenizer, max_length):\n    tokens = tokenizer(example['text'])[:max_length]\n    length = len(tokens)\n    return {'tokens': tokens, 'length': length}","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:28.971446Z","iopub.execute_input":"2022-02-08T13:29:28.972264Z","iopub.status.idle":"2022-02-08T13:29:28.981852Z","shell.execute_reply.started":"2022-02-08T13:29:28.972203Z","shell.execute_reply":"2022-02-08T13:29:28.980505Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizing the dataset (also creates a padding if there words are less than max length)","metadata":{}},{"cell_type":"code","source":"max_length = 256\n\ntrain_data = train_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})\ntest_data = test_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:28.983523Z","iopub.execute_input":"2022-02-08T13:29:28.984294Z","iopub.status.idle":"2022-02-08T13:29:48.073619Z","shell.execute_reply.started":"2022-02-08T13:29:28.984229Z","shell.execute_reply":"2022-02-08T13:29:48.072631Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Creating a validation dataset (as the imdb dataset only has train and test set)","metadata":{}},{"cell_type":"code","source":"valid_size= 0.1\n\ntrain_valid_data = train_data.train_test_split(test_size=valid_size)\ntrain_data = train_valid_data['train']\nvalid_data = train_valid_data['test']\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:48.077418Z","iopub.execute_input":"2022-02-08T13:29:48.077677Z","iopub.status.idle":"2022-02-08T13:29:48.129036Z","shell.execute_reply.started":"2022-02-08T13:29:48.077648Z","shell.execute_reply":"2022-02-08T13:29:48.127908Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Including words that occur minimum 5 times","metadata":{}},{"cell_type":"code","source":"min_freq = 5\nspecial_tokens = ['<unk>', '<pad>']\n\nvocab = torchtext.vocab.build_vocab_from_iterator(train_data['tokens'],\n                                                  min_freq=min_freq,\n                                                  specials=special_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:48.132905Z","iopub.execute_input":"2022-02-08T13:29:48.134354Z","iopub.status.idle":"2022-02-08T13:29:55.521805Z","shell.execute_reply.started":"2022-02-08T13:29:48.133750Z","shell.execute_reply":"2022-02-08T13:29:55.520495Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"unk_index = vocab['<unk>']\npad_index = vocab['<pad>']","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:55.524363Z","iopub.execute_input":"2022-02-08T13:29:55.525187Z","iopub.status.idle":"2022-02-08T13:29:55.532380Z","shell.execute_reply.started":"2022-02-08T13:29:55.525139Z","shell.execute_reply":"2022-02-08T13:29:55.530993Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\nvocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:55.539865Z","iopub.execute_input":"2022-02-08T13:29:55.540720Z","iopub.status.idle":"2022-02-08T13:29:55.547240Z","shell.execute_reply.started":"2022-02-08T13:29:55.540618Z","shell.execute_reply":"2022-02-08T13:29:55.545262Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"##  Function for converting the tokens into numbers according to their index\n","metadata":{}},{"cell_type":"code","source":"def numericalize_data(example, vocab):\n    ids = [vocab[token] for token in example['tokens']]\n    return {'ids': ids}","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:55.549662Z","iopub.execute_input":"2022-02-08T13:29:55.550736Z","iopub.status.idle":"2022-02-08T13:29:55.559499Z","shell.execute_reply.started":"2022-02-08T13:29:55.550687Z","shell.execute_reply":"2022-02-08T13:29:55.557558Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\nvalid_data = valid_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\ntest_data = test_data.map(numericalize_data, fn_kwargs={'vocab': vocab})","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:29:55.563890Z","iopub.execute_input":"2022-02-08T13:29:55.566772Z","iopub.status.idle":"2022-02-08T13:30:32.964774Z","shell.execute_reply.started":"2022-02-08T13:29:55.566730Z","shell.execute_reply":"2022-02-08T13:30:32.963909Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Converting the data to pytorch tensors","metadata":{}},{"cell_type":"code","source":"train_data = train_data.with_format(type='torch', columns=['ids', 'label', 'length'])\nvalid_data = valid_data.with_format(type='torch', columns=['ids', 'label', 'length'])\ntest_data = test_data.with_format(type='torch', columns=['ids', 'label', 'length'])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:32.967609Z","iopub.execute_input":"2022-02-08T13:30:32.968172Z","iopub.status.idle":"2022-02-08T13:30:32.981204Z","shell.execute_reply.started":"2022-02-08T13:30:32.968127Z","shell.execute_reply":"2022-02-08T13:30:32.978067Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data[5]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:32.983335Z","iopub.execute_input":"2022-02-08T13:30:32.983900Z","iopub.status.idle":"2022-02-08T13:30:33.379945Z","shell.execute_reply.started":"2022-02-08T13:30:32.983844Z","shell.execute_reply":"2022-02-08T13:30:33.378874Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Class for LSTM model ","metadata":{}},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional,\n                 dropout_rate, pad_index):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n                            dropout=dropout_rate, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout_rate)\n        \n    def forward(self, ids, length):\n        # ids = [batch size, seq len]\n        # length = [batch size]\n        embedded = self.dropout(self.embedding(ids))\n        # embedded = [batch size, seq len, embedding dim]\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, length, batch_first=True, \n                                                            enforce_sorted=False)\n        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n        # hidden = [n layers * n directions, batch size, hidden dim]\n        # cell = [n layers * n directions, batch size, hidden dim]\n        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n        # output = [batch size, seq len, hidden dim * n directions]\n        if self.lstm.bidirectional:\n            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n            # hidden = [batch size, hidden dim * 2]\n        else:\n            hidden = self.dropout(hidden[-1])\n            # hidden = [batch size, hidden dim]\n        prediction = self.fc(hidden)\n        # prediction = [batch size, output dim]\n        return prediction","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:33.381995Z","iopub.execute_input":"2022-02-08T13:30:33.382319Z","iopub.status.idle":"2022-02-08T13:30:33.394394Z","shell.execute_reply.started":"2022-02-08T13:30:33.382275Z","shell.execute_reply":"2022-02-08T13:30:33.393103Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Setting the dimensions ","metadata":{}},{"cell_type":"code","source":"vocab_size = len(vocab)\nembedding_dim = 300\nhidden_dim = 300\noutput_dim = len(train_data.unique('label'))\nn_layers = 2\nbidirectional = True\ndropout_rate = 0.5\n\nmodel = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n             pad_index)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:33.396311Z","iopub.execute_input":"2022-02-08T13:30:33.397349Z","iopub.status.idle":"2022-02-08T13:30:33.519057Z","shell.execute_reply.started":"2022-02-08T13:30:33.397303Z","shell.execute_reply":"2022-02-08T13:30:33.517896Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Counting the number of parameters","metadata":{}},{"cell_type":"code","source":"\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:33.521400Z","iopub.execute_input":"2022-02-08T13:30:33.521640Z","iopub.status.idle":"2022-02-08T13:30:33.530649Z","shell.execute_reply.started":"2022-02-08T13:30:33.521611Z","shell.execute_reply":"2022-02-08T13:30:33.529662Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"\n## Initialzing the parameters(weights and biases) for the layers using methods like Xavier initialization .....","metadata":{}},{"cell_type":"code","source":"def initialize_weights(m):\n    if isinstance(m, nn.Linear):\n        nn.init.xavier_normal_(m.weight)\n        nn.init.zeros_(m.bias)\n    elif isinstance(m, nn.LSTM):\n        for name, param in m.named_parameters():\n            if 'bias' in name:\n                nn.init.zeros_(param)\n            elif 'weight' in name:\n                nn.init.orthogonal_(param)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:33.532801Z","iopub.execute_input":"2022-02-08T13:30:33.533563Z","iopub.status.idle":"2022-02-08T13:30:33.546813Z","shell.execute_reply.started":"2022-02-08T13:30:33.533503Z","shell.execute_reply":"2022-02-08T13:30:33.545861Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Applying the initial parameter values","metadata":{}},{"cell_type":"code","source":"model.apply(initialize_weights)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:33.548548Z","iopub.execute_input":"2022-02-08T13:30:33.548952Z","iopub.status.idle":"2022-02-08T13:30:33.821382Z","shell.execute_reply.started":"2022-02-08T13:30:33.548864Z","shell.execute_reply":"2022-02-08T13:30:33.820255Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Downloading pre-trained word embeddings ","metadata":{}},{"cell_type":"code","source":"vectors = torchtext.vocab.FastText()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:30:33.823164Z","iopub.execute_input":"2022-02-08T13:30:33.823722Z","iopub.status.idle":"2022-02-08T13:41:57.412833Z","shell.execute_reply.started":"2022-02-08T13:30:33.823676Z","shell.execute_reply":"2022-02-08T13:41:57.410926Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:41:57.418422Z","iopub.execute_input":"2022-02-08T13:41:57.418759Z","iopub.status.idle":"2022-02-08T13:41:57.709524Z","shell.execute_reply.started":"2022-02-08T13:41:57.418720Z","shell.execute_reply":"2022-02-08T13:41:57.708425Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Initialing the parmeterts of embedding layer using pre-trained embeddings","metadata":{}},{"cell_type":"code","source":"model.embedding.weight.data = pretrained_embedding","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:41:57.711232Z","iopub.execute_input":"2022-02-08T13:41:57.711912Z","iopub.status.idle":"2022-02-08T13:41:58.551615Z","shell.execute_reply.started":"2022-02-08T13:41:57.711863Z","shell.execute_reply":"2022-02-08T13:41:58.550545Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Initializing learning rate and optimizer","metadata":{}},{"cell_type":"code","source":"lr = 5e-4\n\noptimizer = optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:41:58.553114Z","iopub.execute_input":"2022-02-08T13:41:58.553443Z","iopub.status.idle":"2022-02-08T13:41:59.128592Z","shell.execute_reply.started":"2022-02-08T13:41:58.553398Z","shell.execute_reply":"2022-02-08T13:41:59.127403Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"\n## The loss function we'll use is the cross-entropy loss","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:41:59.130123Z","iopub.execute_input":"2022-02-08T13:41:59.130566Z","iopub.status.idle":"2022-02-08T13:41:59.381277Z","shell.execute_reply.started":"2022-02-08T13:41:59.130519Z","shell.execute_reply":"2022-02-08T13:41:59.379861Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Checking whether GPU is available","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:41:59.384779Z","iopub.execute_input":"2022-02-08T13:41:59.385699Z","iopub.status.idle":"2022-02-08T13:41:59.763709Z","shell.execute_reply.started":"2022-02-08T13:41:59.385642Z","shell.execute_reply":"2022-02-08T13:41:59.762663Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Deploying model and lass layer on GPU","metadata":{}},{"cell_type":"code","source":"\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:41:59.765551Z","iopub.execute_input":"2022-02-08T13:41:59.765946Z","iopub.status.idle":"2022-02-08T13:42:04.726335Z","shell.execute_reply.started":"2022-02-08T13:41:59.765857Z","shell.execute_reply":"2022-02-08T13:42:04.725332Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Function to stack sequences ","metadata":{}},{"cell_type":"code","source":"def collate(batch, pad_index):\n    batch_ids = [i['ids'] for i in batch]\n    batch_ids = nn.utils.rnn.pad_sequence(batch_ids, padding_value=pad_index, batch_first=True)\n    batch_length = [i['length'] for i in batch]\n    batch_length = torch.stack(batch_length)\n    batch_label = [i['label'] for i in batch]\n    batch_label = torch.stack(batch_label)\n    batch = {'ids': batch_ids,\n             'length': batch_length,\n             'label': batch_label}\n    return batch","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:42:04.732048Z","iopub.execute_input":"2022-02-08T13:42:04.735383Z","iopub.status.idle":"2022-02-08T13:42:04.747137Z","shell.execute_reply.started":"2022-02-08T13:42:04.735333Z","shell.execute_reply":"2022-02-08T13:42:04.746257Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Creating dataloaders to put batches on GPU","metadata":{}},{"cell_type":"code","source":"batch_size = 64\n\ncollate = functools.partial(collate, pad_index=pad_index)\n\ntrain_dataloader = torch.utils.data.DataLoader(train_data, \n                                               batch_size=batch_size, \n                                               collate_fn=collate, \n                                               shuffle=True)\n\nvalid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, collate_fn=collate)\ntest_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, collate_fn=collate)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:42:04.758345Z","iopub.execute_input":"2022-02-08T13:42:04.761478Z","iopub.status.idle":"2022-02-08T13:42:04.772285Z","shell.execute_reply.started":"2022-02-08T13:42:04.761394Z","shell.execute_reply":"2022-02-08T13:42:04.771334Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Function for Training ","metadata":{}},{"cell_type":"code","source":"def train(dataloader, model, criterion, optimizer, device):\n\n    model.train()\n    epoch_losses = []\n    epoch_accs = []\n\n    for batch in tqdm.tqdm(dataloader, desc='training...', file=sys.stdout):\n        ids = batch['ids'].to(device)\n        length = batch['length']\n        label = batch['label'].to(device)\n        prediction = model(ids, length)\n        loss = criterion(prediction, label)\n        accuracy = get_accuracy(prediction, label)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_losses.append(loss.item())\n        epoch_accs.append(accuracy.item())\n\n    return epoch_losses, epoch_accs","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:42:04.778193Z","iopub.execute_input":"2022-02-08T13:42:04.781329Z","iopub.status.idle":"2022-02-08T13:42:04.794124Z","shell.execute_reply.started":"2022-02-08T13:42:04.781283Z","shell.execute_reply":"2022-02-08T13:42:04.793135Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Function for evaluating the model","metadata":{}},{"cell_type":"code","source":"def evaluate(dataloader, model, criterion, device):\n    \n    model.eval()\n    epoch_losses = []\n    epoch_accs = []\n\n    with torch.no_grad():\n        for batch in tqdm.tqdm(dataloader, desc='evaluating...', file=sys.stdout):\n            ids = batch['ids'].to(device)\n            length = batch['length']\n            label = batch['label'].to(device)\n            prediction = model(ids, length)\n            loss = criterion(prediction, label)\n            accuracy = get_accuracy(prediction, label)\n            epoch_losses.append(loss.item())\n            epoch_accs.append(accuracy.item())\n\n    return epoch_losses, epoch_accs","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:42:04.800399Z","iopub.execute_input":"2022-02-08T13:42:04.803718Z","iopub.status.idle":"2022-02-08T13:42:04.816523Z","shell.execute_reply.started":"2022-02-08T13:42:04.803655Z","shell.execute_reply":"2022-02-08T13:42:04.815213Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Function to get Accuracy","metadata":{}},{"cell_type":"code","source":"\ndef get_accuracy(prediction, label):\n    batch_size, _ = prediction.shape\n    predicted_classes = prediction.argmax(dim=-1)\n    correct_predictions = predicted_classes.eq(label).sum()\n    accuracy = correct_predictions / batch_size\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:42:04.822104Z","iopub.execute_input":"2022-02-08T13:42:04.825058Z","iopub.status.idle":"2022-02-08T13:42:04.834065Z","shell.execute_reply.started":"2022-02-08T13:42:04.825010Z","shell.execute_reply":"2022-02-08T13:42:04.833048Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"n_epochs = 10\nbest_valid_loss = float('inf')\n\ntrain_losses = []\ntrain_accs = []\nvalid_losses = []\nvalid_accs = []\n\nfor epoch in range(n_epochs):\n\n    train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, device)\n    valid_loss, valid_acc = evaluate(valid_dataloader, model, criterion, device)\n\n    train_losses.extend(train_loss)\n    train_accs.extend(train_acc)\n    valid_losses.extend(valid_loss)\n    valid_accs.extend(valid_acc)\n    \n    epoch_train_loss = np.mean(train_loss)\n    epoch_train_acc = np.mean(train_acc)\n    epoch_valid_loss = np.mean(valid_loss)\n    epoch_valid_acc = np.mean(valid_acc)\n    \n    if epoch_valid_loss < best_valid_loss:\n        best_valid_loss = epoch_valid_loss\n        torch.save(model.state_dict(), 'lstm.pt')\n    \n    print(f'epoch: {epoch+1}')\n    print(f'train_loss: {epoch_train_loss:.3f}, train_acc: {epoch_train_acc:.3f}')\n    print(f'valid_loss: {epoch_valid_loss:.3f}, valid_acc: {epoch_valid_acc:.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:42:04.839836Z","iopub.execute_input":"2022-02-08T13:42:04.842946Z","iopub.status.idle":"2022-02-08T13:52:26.836292Z","shell.execute_reply.started":"2022-02-08T13:42:04.842899Z","shell.execute_reply":"2022-02-08T13:52:26.835218Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nax = fig.add_subplot(1,1,1)\nax.plot(train_losses, label='train loss')\nax.plot(valid_losses, label='valid loss')\nplt.legend()\nax.set_xlabel('updates')\nax.set_ylabel('loss');\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:52:26.838139Z","iopub.execute_input":"2022-02-08T13:52:26.838883Z","iopub.status.idle":"2022-02-08T13:52:27.227004Z","shell.execute_reply.started":"2022-02-08T13:52:26.838835Z","shell.execute_reply":"2022-02-08T13:52:27.225934Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nax = fig.add_subplot(1,1,1)\nax.plot(train_accs, label='train accuracy')\nax.plot(valid_accs, label='valid accuracy')\nplt.legend()\nax.set_xlabel('updates')\nax.set_ylabel('accuracy');\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:52:27.228914Z","iopub.execute_input":"2022-02-08T13:52:27.229193Z","iopub.status.idle":"2022-02-08T13:52:27.553167Z","shell.execute_reply.started":"2022-02-08T13:52:27.229152Z","shell.execute_reply":"2022-02-08T13:52:27.552141Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\n\nepoch_test_loss = np.mean(test_loss)\nepoch_test_acc = np.mean(test_acc)\n\nprint(f'test_loss: {epoch_test_loss:.3f}, test_acc: {epoch_test_acc:.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:52:27.554841Z","iopub.execute_input":"2022-02-08T13:52:27.555621Z","iopub.status.idle":"2022-02-08T13:52:53.898787Z","shell.execute_reply.started":"2022-02-08T13:52:27.555571Z","shell.execute_reply":"2022-02-08T13:52:53.897839Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def predict_sentiment(text, model, tokenizer, vocab, device):\n    tokens = tokenizer(text)\n    ids = [vocab[t] for t in tokens]\n    length = torch.LongTensor([len(ids)])\n    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n    prediction = model(tensor, length).squeeze(dim=0)\n    probability = torch.softmax(prediction, dim=-1)\n    predicted_class = prediction.argmax(dim=-1).item()\n    predicted_probability = probability[predicted_class].item()\n    return predicted_class, predicted_probability","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:52:53.903621Z","iopub.execute_input":"2022-02-08T13:52:53.904411Z","iopub.status.idle":"2022-02-08T13:52:53.918147Z","shell.execute_reply.started":"2022-02-08T13:52:53.904338Z","shell.execute_reply":"2022-02-08T13:52:53.917190Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"text = \"This film is terrible!\"\n\npredict_sentiment(text, model, tokenizer, vocab, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:55:23.653620Z","iopub.execute_input":"2022-02-08T13:55:23.653925Z","iopub.status.idle":"2022-02-08T13:55:23.679952Z","shell.execute_reply.started":"2022-02-08T13:55:23.653894Z","shell.execute_reply":"2022-02-08T13:55:23.679068Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\ntext = \"This film is great!\"\n\npredict_sentiment(text, model, tokenizer, vocab, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:55:35.393055Z","iopub.execute_input":"2022-02-08T13:55:35.393386Z","iopub.status.idle":"2022-02-08T13:55:35.405274Z","shell.execute_reply.started":"2022-02-08T13:55:35.393337Z","shell.execute_reply":"2022-02-08T13:55:35.404008Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"text = \"This film is not terrible, it's great!\"\n\npredict_sentiment(text, model, tokenizer, vocab, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:55:43.411507Z","iopub.execute_input":"2022-02-08T13:55:43.411891Z","iopub.status.idle":"2022-02-08T13:55:43.431844Z","shell.execute_reply.started":"2022-02-08T13:55:43.411850Z","shell.execute_reply":"2022-02-08T13:55:43.431007Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\ntext = \"This film is not great, it's terrible!\"\n\npredict_sentiment(text, model, tokenizer, vocab, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:55:51.381817Z","iopub.execute_input":"2022-02-08T13:55:51.382137Z","iopub.status.idle":"2022-02-08T13:55:51.396045Z","shell.execute_reply.started":"2022-02-08T13:55:51.382097Z","shell.execute_reply":"2022-02-08T13:55:51.394994Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}